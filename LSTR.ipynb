{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br5b5wfq4SAB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlGFh5Qzbzw_"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/MyDrive /mydrive\n",
        "!ls /mydrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIen9QMMcPhN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 64\n",
        "\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/mydrive/LSTR/logo/',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=100,\n",
        "    validation_split=0.1,\n",
        "    subset=\"training\")\n",
        "\n",
        "ds_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/mydrive/LSTR/logo/',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=100,\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GWb01UKnKJN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y = np.concatenate([y for x,y in ds_train], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J43xno_vnVzd"
      },
      "outputs": [],
      "source": [
        "val, count = np.unique(y, return_counts=True)\n",
        "\n",
        "total = np.sum(count)\n",
        "classes = len(count)\n",
        "\n",
        "class_weight = {}\n",
        "for i, value in enumerate(val):\n",
        "  class_weight[value] = (1/count[i])*(total/classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz4Woud5OhS1"
      },
      "outputs": [],
      "source": [
        "print(class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSVvD6QXhnDS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from tensorflow.keras import initializers\n",
        "from keras import backend\n",
        "from keras.engine import training\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import VersionAwareLayers\n",
        "from keras.utils import data_utils\n",
        "from keras.utils import layer_utils\n",
        "\n",
        "def VGG16CAM(classes=2, input_tensor=None, input_shape=None,\n",
        "             weights=None, pooling=None, num_input_channels=1024):\n",
        "\n",
        "  layers = VersionAwareLayers()\n",
        "  #tf.keras.backend.set_image_data_format('channels_first')\n",
        "  input_shape = imagenet_utils.obtain_input_shape(\n",
        "      input_shape, default_size = 224, min_size=32,\n",
        "      data_format=backend.image_data_format(),\n",
        "      require_flatten=True,\n",
        "      weights=weights)\n",
        "\n",
        "  if input_tensor is None:\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "  else:\n",
        "    if not backend.is_keras_tensor(input_tensor):\n",
        "      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "    else:\n",
        "      img_input = input_tensor\n",
        "  #Block 1\n",
        "  x = layers.Conv2D(64, (3,3), activation='relu',\n",
        "                    padding='same', name='block1_conv1')(img_input)\n",
        "  x = layers.Conv2D(64, (3,3), activation='relu',\n",
        "                    padding='same', name='block1_conv2')(x)\n",
        "  x = layers.MaxPooling2D((2,2), strides=(2,2), name='block1_pool')(x)\n",
        "  #Block 2\n",
        "  x = layers.Conv2D(128, (3,3), activation='relu',\n",
        "                    padding='same', name='block2_conv1')(x)\n",
        "  x = layers.Conv2D(128, (3,3), activation='relu',\n",
        "                    padding='same', name='block2_conv2')(x)\n",
        "  x = layers.MaxPooling2D((2,2), strides=(2,2), name='block2_pool')(x)\n",
        "  #Block 3\n",
        "  x = layers.Conv2D(256, (3, 3), activation='relu',\n",
        "                    padding='same', name='block3_conv1')(x)\n",
        "  x = layers.Conv2D(256, (3, 3), activation='relu',\n",
        "                    padding='same', name='block3_conv2')(x)\n",
        "  x = layers.Conv2D(256, (3, 3), activation='relu',\n",
        "                    padding='same', name='block3_conv3')(x)\n",
        "  x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "  #Block 4\n",
        "  x = layers.Conv2D(512, (3, 3), activation='relu',\n",
        "                    padding='same', name='block4_conv1')(x)\n",
        "  x = layers.Conv2D(512, (3, 3), activation='relu',\n",
        "                    padding='same', name='block4_conv2')(x)\n",
        "  x = layers.Conv2D(512, (3, 3), activation='relu',\n",
        "                    padding='same', name='block4_conv3')(x)\n",
        "  x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "  #Block 5\n",
        "  x = layers.Conv2D(512, (3, 3), activation='relu',\n",
        "                    padding='same', name='block5_conv1')(x)\n",
        "  x = layers.Conv2D(512, (3, 3), activation='relu',\n",
        "                    padding='same', name='block5_conv2')(x)\n",
        "  x = layers.Conv2D(512, (3, 3), activation='relu',\n",
        "                    padding='same', name='block5_conv3')(x)\n",
        "  #Added Conv Layers\n",
        "  x = layers.Conv2D(num_input_channels, (3,3), activation='relu',\n",
        "                    padding='same', name='CAM_conv')(x)\n",
        "  #GMP or GAP\n",
        "\n",
        "  if pooling == 'avg':\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "  elif pooling == 'max':\n",
        "    x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(classes, activation='softmax',\n",
        "                   use_bias=False,name='prediction')(x)  \n",
        "  if input_tensor is not None:\n",
        "    inputs = layer_utils.get_source_inputs(input_tensor)\n",
        "  else:\n",
        "    inputs = img_input\n",
        "  model = training.Model(inputs, x, name='VGG16CAM')\n",
        "  #Load Weights\n",
        "  if weights is not None:\n",
        "    model.load_weights(weights)\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xpvFSocIQR4"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = VGG16CAM(classes=2, weights=None, pooling='avg')\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDFphe4NQhpv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "path = '/content/drive/MyDrive/LSTR/CAMSA_3classes'\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = path,\n",
        "    verbose = 1,\n",
        "    save_weights_only = False,\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS9Yv4OrXzUX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "new_model = tf.keras.models.load_model(path)\n",
        "new_model.evaluate(ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(path)\n",
        "model.evaluate(ds_val)"
      ],
      "metadata": {
        "id": "3BG2Wx12uLbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgWJVeUeL3uM"
      },
      "outputs": [],
      "source": [
        "model.fit(ds_train, epochs=100, verbose=2, validation_data=ds_val, callbacks=cp_callback, class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "XnXGY_wwEReP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW4zAwDSTXCw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.engine import training\n",
        "model_path = '/content/drive/MyDrive/LSTR/CAMSA_3classes'\n",
        "\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "intermediate_layer_model = training.Model(inputs=model.input, outputs=model.layers[-4].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeVfwQAvNgiU"
      },
      "outputs": [],
      "source": [
        "def create_cmap(feature_blobs, softmax_weights):\n",
        "  return np.dot(feature_blobs, softmax_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq6q6b7XsDr0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_cmap(cmap, img_tensor, class_idx, ratio=16):\n",
        "  for i,_ in enumerate(cmap):\n",
        "    fig = plt.figure(figsize=(30,6))\n",
        "    #ax = fig.add_subplot(1, len(class_idx),1)\n",
        "    for idx in class_idx:\n",
        "      ax = fig.add_subplot(1, len(class_idx), idx+1)\n",
        "      img = cmap[i,:,:,idx]\n",
        "      img = cv2.resize(img, (img.shape[0]*ratio, img.shape[1]*ratio), interpolation=cv2.INTER_LINEAR)\n",
        "      img = img - np.min(img)\n",
        "      img = img/np.max(img)\n",
        "      img = np.uint8(255*img)\n",
        "      ax.imshow(img_tensor[i])\n",
        "      ax.imshow(img, cmap='jet', alpha=0.5, interpolation='nearest')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qMq4yMqcNxU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/MyDrive/LSTR/logo/hybrid/1480647.jpeg'\n",
        "\n",
        "im = cv2.resize(cv2.imread(img_path), (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "feature_blobs = intermediate_layer_model.predict(np.expand_dims(im, axis=0))\n",
        "softmax_weights = model.layers[-1].get_weights()[0]\n",
        "cmap = np.dot(feature_blobs, softmax_weights)\n",
        "\n",
        "img = cmap[0,:,:,0]\n",
        "#img = cv2.resize(img, (img.shape[0]*ratio, img.shape[1]*ratio), interpolation=cv2.INTER_LINEAR)\n",
        "img = img - np.min(img)\n",
        "img = img/np.max(img)\n",
        "img = np.uint8(255*img)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-Apd_MOPQVC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "path = '/content/drive/MyDrive/LSTR/logo/hybrid'\n",
        "img_array = []\n",
        "\n",
        "for img_file in os.listdir(path):\n",
        "  img_path = os.path.join(path, img_file)\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.resize(image, (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  img_array.append(image)\n",
        "\n",
        "img_tensor = tf.convert_to_tensor(img_array)\n",
        "feature_blobs = intermediate_layer_model.predict(img_tensor)\n",
        "softmax_weights = model.layers[-1].get_weights()[0]\n",
        "cmap = create_cmap(feature_blobs, softmax_weights)\n",
        "plot_cmap(cmap, img_tensor, [0,1,2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tmp = np.reshape(cmap[:,:,:,1], -1)\n",
        "_ = plt.hist(tmp, bins=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "91TCuFUVUItm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def map_range(left_old, right_old, left_new, right_new, v):\n",
        "  range_old = right_old - left_old\n",
        "  range_new = right_new - left_new\n",
        "\n",
        "  v = (v-left_old)/(range_old)\n",
        "\n",
        "  v = left_new + v*range_new\n",
        "  return v\n",
        "\n",
        "def create_attention_map(text_cmap):\n",
        "  tmp = np.reshape(text_cmap, -1)\n",
        "  #tmp[tmp<=0] = 0\n",
        "  tmp = 1.5*(tmp-np.min(tmp))/(np.max(tmp)-np.min(tmp))\n",
        "  tmp = np.reshape(tmp, text_cmap.shape)\n",
        "  return tmp"
      ],
      "metadata": {
        "id": "KYozpnxBfIIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "def distance(v1,v2, d_type='cosine'):\n",
        "  if d_type == 'd1':\n",
        "    return  np.sum(np.absolute(v1-v2))\n",
        "  elif d_type =='d2':\n",
        "    return np.sum((v1-v2)**2)\n",
        "  elif d_type =='cosine':\n",
        "    v1 = np.reshape(v1, -1)\n",
        "    v2 = np.reshape(v2, -1)\n",
        "    return spatial.distance.cosine(v1,v2)"
      ],
      "metadata": {
        "id": "qxWvUhg6iYnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.engine import training\n",
        "\n",
        "path = '/content/drive/MyDrive/LSTR/database'\n",
        "img_array = []\n",
        "\n",
        "for img_file in os.listdir(path):\n",
        "  img_path = os.path.join(path, img_file)\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.resize(image, (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  img_array.append(image)\n",
        "\n",
        "img_tensor = tf.convert_to_tensor(img_array, dtype=np.uint8)\n",
        "del img_array\n",
        "feature_blobs = intermediate_layer_model.predict(img_tensor)\n",
        "softmax_weights = model.layers[-1].get_weights()[0]\n",
        "cmap = create_cmap(feature_blobs, softmax_weights)\n",
        "del feature_blobs\n",
        "del softmax_weights\n",
        "figure_cmap = cmap[:,:,:,1]\n",
        "#text_cmap = cmap[:,:,:,2]\n",
        "\n",
        "\n",
        "vgg16 = VGG16(weights='imagenet')\n",
        "feature_extractor = training.Model(inputs=vgg16.input, outputs=vgg16.layers[-6].output)\n",
        "features = feature_extractor.predict(preprocess_input(img_tensor))\n",
        "\n",
        "feature_with_attention = np.einsum('ijkz,ijk->ijkz', features, figure_cmap)\n",
        "img_feature_vector = tf.keras.layers.GlobalMaxPool2D()(feature_with_attention)\n",
        "\n",
        "d = np.zeros((len(img_tensor),len(img_tensor)))\n",
        "for i in range(len(img_tensor)):\n",
        "  v1 = img_feature_vector[i]\n",
        "  d[i,i] = 0\n",
        "  for j in range(i+1, len(img_tensor)):\n",
        "    v2 = img_feature_vector[j]\n",
        "    d[i,j] = distance(v1, v2, d_type='cosine')\n",
        "    d[j,i] = d[i,j]"
      ],
      "metadata": {
        "id": "62sjpYxqnDEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=5\n",
        "for i in range(len(img_tensor)):\n",
        "  fig = plt.figure(figsize=(30,6))\n",
        "  ax = fig.add_subplot(1, n+1, 1)\n",
        "  ax.imshow(img_tensor[i])\n",
        "  tmp = d[i]\n",
        "  query = np.argsort(tmp)\n",
        "  for j in range(n):\n",
        "    ax = fig.add_subplot(1, n+1, j+2)\n",
        "    ax.imshow(img_tensor[query[j+1]])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "cX_LBWrMhA4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.engine import training\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Input paths\n",
        "query_path = '/content/drive/MyDrive/LSTR/logo/shape/mickey-mouse-character-vector-400x400.png' #the image we want to query\n",
        "database_path = '/content/drive/MyDrive/LSTR/logo/shape'\n",
        "model_path = '/content/drive/MyDrive/LSTR/CAMSA_3classes'\n",
        "\n",
        "#Class activation map model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "intermediate_layer_model = training.Model(inputs=model.input, outputs=model.layers[-4].output)\n",
        "\n",
        "#Save database into tensor\n",
        "query_image = cv2.imread(query_path)\n",
        "query_image = cv2.resize(query_image, (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
        "query_tensor = tf.convert_to_tensor(np.expand_dims(query_image, axis=0), dtype=np.uint8)\n",
        "\n",
        "img_array = []\n",
        "for img_file in os.listdir(database_path):\n",
        "  img_path = os.path.join(database_path, img_file)\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.resize(image, (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #as opencv read image as BGR\n",
        "  img_array.append(image)\n",
        "database_tensor = tf.convert_to_tensor(img_array, dtype=np.uint8)\n",
        "\n",
        "#Create Class Activation Map\n",
        "query_feature_blob = intermediate_layer_model.predict(query_tensor) #shape = [1, 14,14,1024]\n",
        "feature_blobs = intermediate_layer_model.predict(database_tensor) #shape = [bs, 14,14,1024] (1024 channels, each is a 14x14 image)\n",
        "\n",
        "softmax_weights = model.layers[-1].get_weights()[0] #shape = [1024, 3] (1024 weights for 3 classes)\n",
        "\n",
        "query_figure_cmap = create_cmap(query_feature_blob, softmax_weights)[:,:,:,1] #shape = [1, 14, 14], change the last index to choose your cmap\n",
        "figure_cmap = create_cmap(feature_blobs, softmax_weights)[:,:,:,1] #shape = [bs, 14, 14]\n",
        "\n",
        "#Create feature extractor\n",
        "vgg16 = VGG16(weights='imagenet')\n",
        "feature_extractor = training.Model(inputs=vgg16.input, outputs=vgg16.layers[-6].output) #output of block5_conv3\n",
        "#Save features into tensor\n",
        "query_feature = feature_extractor.predict(preprocess_input(query_tensor)) #shape = [1,14,14,512] \n",
        "features = feature_extractor.predict(preprocess_input(database_tensor)) #shape = [bs, 14,14,512] (512 channels, each is a 14x14 image)\n",
        "\n",
        "#Attention & MAC\n",
        "query_with_attention = np.einsum('ijkz,ijk->ijkz', query_feature, query_figure_cmap)\n",
        "feature_with_attention = np.einsum('ijkz,ijk->ijkz', features, figure_cmap)\n",
        "query_feature_vector = tf.keras.layers.GlobalMaxPool2D()(query_with_attention)\n",
        "img_feature_vector = tf.keras.layers.GlobalMaxPool2D()(feature_with_attention)\n",
        "\n",
        "#Create Distance Vector (einsum is faster than normal matrix multiplication)\n",
        "d = np.zeros(len(database_tensor))\n",
        "v1 = query_feature_vector\n",
        "for j in range(len(database_tensor)):\n",
        "  v2 = img_feature_vector[j]\n",
        "  d[j] = distance(v1,v2, d_type='cosine')\n",
        "\n",
        "#Return Query\n",
        "n=5\n",
        "fig = plt.figure(figsize=(30,6))\n",
        "ax = fig.add_subplot(1, n+1, 1)\n",
        "ax.imshow(query_image)\n",
        "index = np.argsort(d)\n",
        "for j in range(n):\n",
        "  ax = fig.add_subplot(1, n+1, j+2)\n",
        "  ax.imshow(database_tensor[index[j]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8-tcSdxJixlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmrI-x85X3e3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from tensorflow.keras import initializers\n",
        "from keras import backend\n",
        "from keras.engine import training\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import VersionAwareLayers\n",
        "from keras.utils import data_utils\n",
        "from keras.utils import layer_utils\n",
        "\n",
        "def UNet():\n",
        "  layers = VersionAwareLayers()\n",
        "  #tf.keras.backend.set_image_data_format('channels_first')\n",
        "  input_shape = imagenet_utils.obtain_input_shape(\n",
        "      input_shape, default_size = 224, min_size=32,\n",
        "      data_format=backend.image_data_format(),\n",
        "      require_flatten=True,\n",
        "      weights=weights)\n",
        "\n",
        "  if input_tensor is None:\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "  else:\n",
        "    if not backend.is_keras_tensor(input_tensor):\n",
        "      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "    else:\n",
        "      img_input = input_tensor\n",
        "  #Downsampling block\n",
        "  x = layers.Conv2D(64, (3,3), activation='relu', name='Down_Conv1', padding='same')(img_input)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTR.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}